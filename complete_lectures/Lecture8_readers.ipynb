{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# COLX 521 Lecture 8: Corpus Readers\n",
    "\n",
    "* NLTK corpus readers (A closer look)\n",
    "* Classes revisited\n",
    "* Generator functions\n",
    "* Building corpus readers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK corpus readers (a closer look)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We've been accessing corpora in NLTK using something that looks like method of some module or object which is specific to each corpus. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#provided code\n",
    "from nltk.corpus import brown\n",
    "\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does NLTK really have a totally separate corpus reader for all of its corpora? Actually, no. If you look at the code for the nltk.corpus module, you find the definitions of the corpus readers we have been using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provided code\n",
    "# from \\Lib\\site-packages\\nltk\\corpus\\__init__.py\n",
    "\n",
    "from nltk.corpus.util import LazyCorpusLoader\n",
    "from nltk.corpus.reader import *\n",
    "\n",
    "\n",
    "brown = LazyCorpusLoader(\n",
    "    'brown',\n",
    "    CategorizedTaggedCorpusReader,\n",
    "    r'c[a-z]\\d\\d',\n",
    "    cat_file='cats.txt',\n",
    "    tagset='brown',\n",
    "    encoding=\"ascii\",\n",
    ")\n",
    "\n",
    "gutenberg = LazyCorpusLoader(\n",
    "    'gutenberg', PlaintextCorpusReader, r'(?!\\.).*\\.txt', encoding='latin1'\n",
    ")\n",
    "\n",
    "movie_reviews = LazyCorpusLoader(\n",
    "    'movie_reviews',\n",
    "    CategorizedPlaintextCorpusReader,\n",
    "    r'(?!\\.).*\\.txt',\n",
    "    cat_pattern=r'(neg|pos)/.*',\n",
    "    encoding='ascii',\n",
    ")\n",
    "\n",
    "switchboard = LazyCorpusLoader('switchboard', SwitchboardCorpusReader, tagset='wsj')\n",
    "\n",
    "reuters = LazyCorpusLoader(\n",
    "    'reuters',\n",
    "    CategorizedPlaintextCorpusReader,\n",
    "    '(training|test).*',\n",
    "    cat_file='cats.txt',\n",
    "    encoding='ISO-8859-2',\n",
    ")\n",
    "\n",
    "movie_reviews = LazyCorpusLoader(\n",
    "    'movie_reviews',\n",
    "    CategorizedPlaintextCorpusReader,\n",
    "    r'(?!\\.).*\\.txt',\n",
    "    cat_pattern=r'(neg|pos)/.*',\n",
    "    encoding='ascii',\n",
    ")\n",
    "\n",
    "\n",
    "treebank = LazyCorpusLoader(\n",
    "    'treebank/combined',\n",
    "    BracketParseCorpusReader,\n",
    "    r'wsj_.*\\.mrg',\n",
    "    tagset='wsj',\n",
    "    encoding='ascii',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are wrapped in a \"LazyCorpusLoader\" object but that's just a trick to stop the corpus from being loaded before it is used; the object that actually being accessed when when we run `words()` etc. are the various corpus readers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CategorizedTaggedCorpusReader in '.../corpora/brown' (not loaded yet)>\n"
     ]
    }
   ],
   "source": [
    "print(brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PlaintextCorpusReader in '.../corpora/gutenberg' (not loaded yet)>\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BracketParseCorpusReader in '.../corpora/treebank/combined' (not loaded yet)>\n"
     ]
    }
   ],
   "source": [
    "print(treebank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some corpora require special readers (e.g. Switchboard), but there are a few basic kinds that we can for our own corpora. The simpliest is the PlaintextCorpusReader. Let's create some plain text, and load it using a NLTK corpus reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dr', '.', 'Brooke', 'got', 'his', 'Ph', '.', 'D', '.', 'from', 'the', 'Univ', '.']\n",
      "['of', 'Toronto', 'on', '12', '/', '2013', '.']\n",
      "['Dr', '.', 'Brooke', \"'\", 's', 'GPA', 'was', '4', '.', '1', ',', 'and', 'his', 'thesis', 'wasn', \"'\", 't', 'half', '-', 'bad', ',', 'if', 'a', 'bit', 'too', 'long', '.']\n",
      "['He', 'went', 'into', 'industry', '...', 'but', 'later', 'came', 'back', 'to', 'academia', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Dr. Brooke got his Ph.D. from the Univ. of Toronto on 12/2013. Dr. Brooke's GPA was 4.1, and his thesis wasn't half-bad, if a bit too long. He went into industry...but later came back to academia.\"\n",
    "fout = open(\"test.txt\",\"w\",encoding=\"ascii\")\n",
    "fout.write(text)\n",
    "fout.close()\n",
    "\n",
    "#my code here\n",
    "reader = PlaintextCorpusReader(\"./\", \"test.txt\",encoding=\"latin-1\")\n",
    "for sent in reader.sents():\n",
    "    print(sent)\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one other NLTK CorpusReader,TaggedCorpusReader, which reads a format that should be somewhat familiar by now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'AT'), ('fulton', 'NP'), ('county', 'NN'), ('grand', 'JJ'), ('jury', 'NN'), ('said', 'VBD'), ('friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '')]\n",
      "[('Lebanon', 'NP1'), ('leader', 'NN1'), ('builds', 'VVZ'), ('cabinet', 'NN1'), ('.', 'YSTP')]\n"
     ]
    }
   ],
   "source": [
    "text1 = \"The/AT Fulton/NP County/NN grand/JJ jury/NN said/VBD Friday/NR an/AT investigation/NN of/IN Atlanta's/NP$ recent/JJ primary/NN election/NN produced/VBD ``/`` no/AT evidence/NN ''/'' that/CS any/DTI irregularities/NNS took/VBD place/NN ./\"\n",
    "text2 = \"Lebanon/NP1 leader/NN1 builds/VVZ cabinet/NN1 ./YSTP\\n\"\n",
    "fout = open(\"test1.txt\",\"w\",encoding=\"ascii\")\n",
    "fout.write(text1)\n",
    "fout.close()\n",
    "fout = open(\"test2.txt\",\"w\",encoding=\"ascii\")\n",
    "fout.write(text2)\n",
    "fout.close()\n",
    "\n",
    "#my code here\n",
    "reader = TaggedCorpusReader(\"./\", r\"test\\d.txt\",encoding=\"ascii\")\n",
    "for sent in reader.tagged_sents():\n",
    "    print(sent)\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all these Corpus Readers objects are not independent classes. They are subclasses of a general CorpusReader class which contains some methods and variables which are common to all NLTK corpus readers. You can check to see if one class is a subclass of another by using [issubclass](https://docs.python.org/3/library/functions.html#issubclass), and you can see the methods and variables of a class by using the [dir](https://docs.python.org/3/library/functions.html#dir) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(PlaintextCorpusReader,CorpusReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_get_root',\n",
       " 'abspath',\n",
       " 'abspaths',\n",
       " 'citation',\n",
       " 'encoding',\n",
       " 'ensure_loaded',\n",
       " 'fileids',\n",
       " 'license',\n",
       " 'open',\n",
       " 'readme',\n",
       " 'root',\n",
       " 'unicode_repr']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(CorpusReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_get_root',\n",
       " 'abspath',\n",
       " 'abspaths',\n",
       " 'citation',\n",
       " 'encoding',\n",
       " 'ensure_loaded',\n",
       " 'fileids',\n",
       " 'license',\n",
       " 'open',\n",
       " 'paras',\n",
       " 'raw',\n",
       " 'readme',\n",
       " 'root',\n",
       " 'sents',\n",
       " 'tagged_paras',\n",
       " 'tagged_sents',\n",
       " 'tagged_words',\n",
       " 'unicode_repr',\n",
       " 'words']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(TaggedCorpusReader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classes revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this lecture we will consider how we build our own corpus reader for corpora that require special processing. There are a few pieces that we need to put together to get the kind of functionality we see in NLTK. The first is Python classes, which you've of course already built DSCI 511. Let's review this by creating a SimpleFileIO class which will allow a user of the class to write and read to documents in a particular directory (root) and with a particular encoding. Let's start with just the `__init__` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleFileIO:\n",
    "    \n",
    "    def __init__(self, root, encoding):\n",
    "        self.root = root\n",
    "        self.encoding = encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The initialization for the person class we just wrote on a specific, somewhat arbitrary ordering of arguments. It can be easier to use functions/methods which take keywords, allowing for arbitrary ordering. Another useful aspect of keyword arguments is the ability to have defaults, allowing you to leave out arguments entirely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleFileIO:\n",
    "    \n",
    "    def __init__(self, root=\".\", encoding=\"utf-8\"):\n",
    "        self.root = root\n",
    "        self.encoding = encoding      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "#provided code\n",
    "test1 = SimpleFileIO()\n",
    "assert test1.root == \".\"\n",
    "test2 = SimpleFileIO(encoding=\"latin-1\")\n",
    "assert test2.encoding == \"latin-1\"\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, let's add some methods which allow us to write a string to a given file (in our \"root\" directory). One way our SimpleFileIO is going to be different is that instead of just overwriting a file if it already exists, our code will just inform the user that the file existings unless an optional boolean `overwrite` has  True. We will have have a special internal function which checks if the file already exists, which we will also use for writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class SimpleFileIO:\n",
    "    '''easy, safe reading and writing to files in a given directory'''\n",
    "     \n",
    "    def __init__(self, root=\"./\", encoding=\"utf-8\"):\n",
    "        '''\n",
    "        root -- the directory where the files will reside. Create this directory if it doesn't exist\n",
    "        encoding -- the encoding used to open the files\n",
    "        '''\n",
    "        self.root = root if root.endswith(\"/\") else root + \"/\"\n",
    "        self.encoding = encoding\n",
    "        if not os.path.exists(self.root):\n",
    "            os.mkdir(self.root)\n",
    "    \n",
    "    def _file_exists(self, filename):\n",
    "        '''see if filename exists in directory given by self.root'''\n",
    "        return os.path.exists(self.root + filename)\n",
    "    \n",
    "    def write(self,filename,string,overwrite=False):\n",
    "        ''' write a string to a file, if the file doesn't exist or overwrite is True\n",
    "        \n",
    "        filename -- the filename to write to\n",
    "        string -- the contents of the file\n",
    "        overwrite -- True if the file should be written even if it already exists'''\n",
    "        if not overwrite and self._file_exists(filename):\n",
    "            print(filename + \" already exists!\")\n",
    "        else:\n",
    "            fout = open(self.root + filename,\"w\",encoding=self.encoding)\n",
    "            fout.write(string)\n",
    "            fout.close()\n",
    "            \n",
    "    def read(self,filename):\n",
    "        '''read a string from file indicated by filename, will print out a polite warning if file isn't there'''\n",
    "        if not self._file_exists(filename):\n",
    "            print(\"That file doesn't exist, sorry!\")\n",
    "        else:\n",
    "            f = open(self.root + filename, encoding=self.encoding)\n",
    "            text = f.read()\n",
    "            f.close()\n",
    "            return text    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt already exists!\n"
     ]
    }
   ],
   "source": [
    "#provided code\n",
    "test = SimpleFileIO(root=\"test_dir\")\n",
    "test.write(\"test.txt\",\"This is a test\",overwrite=True)\n",
    "test.write(\"test.txt\",\"This shouldn't work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's add some doc strings, and access our doc strings via [help](https://docs.python.org/3/library/functions.html#help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SimpleFileIO in module __main__ object:\n",
      "\n",
      "class SimpleFileIO(builtins.object)\n",
      " |  easy, safe reading and writing to files in a given directory\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root='./', encoding='utf-8')\n",
      " |      root -- the directory where the files will reside. Create this directory if it doesn't exist\n",
      " |      encoding -- the encoding used to open the files\n",
      " |  \n",
      " |  read(self, filename)\n",
      " |      read a string from file indicated by filename, will print out a polite warning if file isn't there\n",
      " |  \n",
      " |  write(self, filename, string, overwrite=False)\n",
      " |      write a string to a file, if the file doesn't exist or overwrite is True\n",
      " |      \n",
      " |      filename -- the filename to write to\n",
      " |      string -- the contents of the file\n",
      " |      overwrite -- True if the file should be written even if it already exists\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Add a `read` method to the class which is analagous to write. It should print out a warning rather than throwing an exception if the file does not exist (it should use \\_file_exists). Write some tests for your method. Then add a doc string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test\n",
      "That file doesn't exist, sorry!\n"
     ]
    }
   ],
   "source": [
    "test.write(\"test.txt\",\"This is a test\",overwrite=True)\n",
    "print(test.read(\"test.txt\"))\n",
    "test.read(\"test2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generator functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we use a corpus reader, we are able to iterate through the words or sentences of an entire corpus just as if the corpus reader had provided us with a list. But the result of words or sents is not actually a list, it is a generator function. The main advantage of an generator is that doesn't have to store everything it intends to return in memory all at once; very important when dealing with large corpora! Generators are used almost exclusively as the iterated objects in for loops. An example of a (built-in) generator in Python 3 is the *range* function (note that in Python 2 *range* did return a list!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#provided code\n",
    "a_big_range = range(10000000000000000000000000000000000000000000000000000)\n",
    "for i in a_big_range:\n",
    "    print(i)\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The trick behind a generator is a function which has a *yield* statment rather than a *return* statement. *return* only happens once in any call to a function, but a *yield* is typically executed mutiple times. Each time a yield statement is executed, the object is returned to the calling function, and the code pauses (remembering the current state) until another object is required by the calling function, at which point it picks up where it left off in the code. In nearly all circumstances, a yield statment will be inside a loop. As a useless example of this, let's create a my_range function which does the same thing as range, using a while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def my_range(n):\n",
    "    i = 0\n",
    "    #my code here\n",
    "    while i < n:\n",
    "        yield i\n",
    "        i+= 1\n",
    "    #my code here\n",
    "        \n",
    "for i in my_range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A slightly more useful example: Let's write an generator that offers up the first n Fibonocci numbers. The Fibonnocci sequence is calculated by summing the previous two numbers in the sequence, starting with a \"base case\" of 0 and 1 (it's typically solved with recursion)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n",
      "34\n",
      "55\n",
      "89\n",
      "144\n",
      "233\n",
      "377\n",
      "610\n",
      "987\n",
      "1597\n",
      "2584\n",
      "4181\n",
      "6765\n",
      "10946\n"
     ]
    }
   ],
   "source": [
    "def fibonacci(n):\n",
    "    prev = 1\n",
    "    prev_prev = 0\n",
    "    count = 0\n",
    "    #my code here\n",
    "    yield 0\n",
    "    yield 1\n",
    "    while count < n:\n",
    "        new = prev + prev_prev\n",
    "        yield new\n",
    "        prev_prev = prev\n",
    "        prev = new\n",
    "        count += 1\n",
    "    #my code here\n",
    "\n",
    "for fib_num in fibonacci(20):\n",
    "    print(fib_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Build a generator which offers up a range from zero to a suppiled n except it skips numbers which have the digit 7 in them or are a multiple of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "15\n",
      "16\n",
      "18\n",
      "19\n",
      "20\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "36\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "48\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "64\n",
      "65\n",
      "66\n",
      "68\n",
      "69\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "85\n",
      "86\n",
      "88\n",
      "89\n",
      "90\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "def non_seven_nums(n):\n",
    "    # your code here\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if \"7\" not in str(i) and not i % 7 == 0:\n",
    "            yield i\n",
    "        i+= 1\n",
    "    # your code here\n",
    "            \n",
    "for non_seven_num in non_seven_nums(100):\n",
    "    print(non_seven_num)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's fairly common to have generators inside generators. Both generators would have yields, and the outer generator would iterator over the former one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "def squares(n):\n",
    "    # my code here\n",
    "    for num in my_range(n):\n",
    "        yield num**2\n",
    "    # my code here\n",
    "\n",
    "\n",
    "for num in squares(10):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One more key difference between generators and regular functions. When you call a regular function (using parenthesis) in any context, it is immediately evaluated and the result returned. This is not true for generators, a generator can be \"called\" (actually just initialized) outside a for loop, assigned, and then used later in a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sum([1,2,3,4])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object my_range at 0x000002530B6C90A0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = my_range(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for num in a:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building corpus readers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A good corpus reader uses classes and generator functions to seamlessly offer up the contents of a large corpus in a consistent pre-processed format to some external user without requiring a huge memory footprint. Normally the corpus involved would be text files on disk, but we could even have a corpus reader that pulls an entire corpus from the web as part of its reading process. Let's do exactly that with some provided pages from the Master of Data Science website. For now, our corpus reader will just offer up words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize\n",
    "pages = [\"https://masterdatascience.ubc.ca/\",\n",
    "         \"https://masterdatascience.ubc.ca/programs/computational-linguistics\",\n",
    "         \"https://masterdatascience.ubc.ca/admissions/frequently-asked-questions\",\n",
    "         \"https://masterdatascience.ubc.ca/why-ubc/our-campuses\"]\n",
    "\n",
    "class MDS_corpus_reader:\n",
    "    \n",
    "    def words(self):\n",
    "        # my code here\n",
    "        for page in pages:\n",
    "            soup = BeautifulSoup(urlopen(page), \"lxml\")\n",
    "            words = word_tokenize(soup.get_text())\n",
    "            for word in words:\n",
    "                yield word\n",
    "\n",
    "        #my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now let's use this corpus reader to build a dictionary of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"''\", 698), (',', 604), ('.', 228), (':', 213), ('and', 203), ('of', 164), ('the', 163), ('to', 135), (':1', 128), ('(', 115), (')', 115), ('Data', 77), ('a', 77), ('UBC', 71), ('for', 70), ('>', 62), ('s', 61), ('in', 61), ('!', 60), ('Science', 57), ('<', 57), ('?', 56), ('--', 52), ('{', 51), ('}', 51), (';', 50), ('[', 49), (']', 49), ('program', 49), ('``', 48), ('MDS', 46), ('The', 45), ('is', 44), ('with', 44), ('data', 40), ('//', 39), (\"'\", 37), ('Vancouver', 37), ('Master', 33), ('Computational', 33), ('Okanagan', 32), ('are', 32), ('on', 32), ('students', 31), (':0', 30), ('campus', 30), ('Linguistics', 29), ('at', 29), ('Students', 26), ('’', 26)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "reader = MDS_corpus_reader()\n",
    "counts = Counter(reader.words())\n",
    "print(counts.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: modify the corpus reader so that it has an option to remove stopwords and nonalphabetic words, and then test it out by building another dictionary of counts; does it look more useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "class MDS_corpus_reader(object):\n",
    "    \n",
    "    def words(self,remove_stopwords=False,remove_non_alpha=False):\n",
    "        for page in pages:\n",
    "            soup = BeautifulSoup(urlopen(page),\"lxml\")\n",
    "            # your code here\n",
    "            words = word_tokenize(soup.get_text())\n",
    "            for word in words:\n",
    "                if (not remove_stopwords or word not in stopwords_set) and (not remove_non_alpha or word.isalpha()):\n",
    "                    yield word\n",
    "            # your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Data', 77), ('UBC', 71), ('Science', 57), ('program', 49), ('MDS', 46), ('The', 45), ('data', 40), ('Vancouver', 37), ('Master', 33), ('Computational', 33), ('Okanagan', 32), ('students', 31), ('campus', 30), ('Linguistics', 29), ('Students', 26), ('courses', 26), ('Instructor', 26), ('Alumni', 22), ('Why', 20), ('language', 19), ('I', 18), ('Stories', 17), ('Subscribe', 17), ('l', 16), ('University', 15), ('British', 15), ('Columbia', 15), ('In', 14), ('Questions', 14), ('Career', 14), ('Us', 14), ('analysis', 14), ('learning', 14), ('experience', 14), ('CDATA', 13), ('Frequently', 13), ('Asked', 13), ('Our', 13), ('application', 13), ('w', 12), ('var', 12), ('link', 12), ('Search', 12), ('Student', 12), ('Campuses', 12), ('How', 12), ('What', 12), ('false', 11), ('take', 11), ('Tuition', 11)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "reader = MDS_corpus_reader()\n",
    "counts = Counter(reader.words(remove_stopwords=True,remove_non_alpha=True))\n",
    "print(counts.most_common(50))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
