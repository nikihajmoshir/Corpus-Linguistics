{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# COLX 521 Lecture 3: Lexicons\n",
    "\n",
    "* Word \"Lists\" (Sets)\n",
    "* Simple dictionary lexicons\n",
    "* Complex lexicons\n",
    "* Lexicons in NLTK\n",
    "* the CMU pronounciation dictionary \n",
    "* File IO for lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word \"Lists\" (Sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The simpliest lexicon is just a list of words that have something in common. For example:\n",
    "\n",
    "* Pronouns (\"he\",\"she\", \"I\", ...)\n",
    "* Negative words (\"terrible\",\"jerk\",\"foolishly\",...)\n",
    "* A list of all family relations (\"father\", \"sister\",...)\n",
    "* The vocabulary of the Brown corpus\n",
    "\n",
    "Typically, one builds a lexicon so that one can identify instances of this word class in some corpus\n",
    "\n",
    "Rule #1: Don't use lists for lexicons. Use [sets](https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fox', 'brown', 'jumped', 'the', 'quick', 'dog', 'over', 'lazy'}\n"
     ]
    }
   ],
   "source": [
    "some_words = [\"the\",\"quick\",\"brown\", \"fox\",\"jumped\", \"over\",\"the\",\"lazy\",\"dog\"]\n",
    "\n",
    "#my code here\n",
    "word_types = set(some_words)\n",
    "print(word_types)\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two big reasons to use sets for lexicons:\n",
    "\n",
    "* Elements are unique\n",
    "* Checking for membership (*in*) is much faster, especially for large lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.6 ms ± 281 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "55.2 ns ± 5.49 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#provided code\n",
    "list_of_nums = list(range(1000000))\n",
    "set_of_nums = set(list_of_nums)\n",
    "test = -1\n",
    "\n",
    "%timeit test in list_of_nums\n",
    "%timeit test in set_of_nums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are a few ways to create sets. If you are starting from scratch, you have to use the *set()* function, but if you are starting with fixed set of existing items you can declare using curly brackets instead of converting a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "family = {\"mother\",\"father\",\"brother\"}\n",
    "months = set()\n",
    "seasons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brother', 'father', 'mother', 'sister'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family.add(\"sister\")\n",
    "family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'january'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months.add(\"january\")\n",
    "months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-03f59ea644c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseasons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "seasons.add(\"spring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is worth memorizing the basic set methods for adding and removing items, including *add*, *update*, and *discard*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "planets = {\"Mars\",\"Venus\", \"Mercury\"}\n",
    "more_planets = [\"Jupiter\",\"Neptune,\",\"Uranus\", \"Pluto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.add(\"Earth\")\n",
    "planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.update(more_planets)\n",
    "planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.discard(\"Pluto\")\n",
    "planets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sets are great for quickly finding intersections using `&` and differences using `-`. Let's find words only in both the Brown and Treebank, and words that appear in only one or the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "from nltk.corpus import brown, treebank\n",
    "\n",
    "brown_vocab = set(brown.words())\n",
    "print('brown vocab: ', len(brown_vocab))\n",
    "treebank_vocab = set(treebank.words())\n",
    "print('treebank vocab: ', len(treebank_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_only = brown_vocab - treebank_vocab\n",
    "print('brown only: ', len(brown_only))\n",
    "treebank_only = treebank_vocab - brown_vocab\n",
    "print('treebank only: ', len(treebank_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_vocab = brown_vocab & treebank_vocab\n",
    "print('in both: ', len(both_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You might sometimes want to intersect a set with something that isn't a set (like a list, or even a string). If so, and it doesn't make sense to convert the other to a set, you can use set methods such as `intersection` instead of operators (which only work both elements are sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = {'a','e','i','o','u','y'}\n",
    "word = \"rstln\"\n",
    "\n",
    "if len(vowels.intersection(word)) == 0:\n",
    "    print(\"no vowels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels & word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some set drawbacks:\n",
    "\n",
    "* No order, no guarantee that order will be perserved when the set changes\n",
    "* Can't add mutuable objects like lists and dicts (use tuples!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "months = [\"Jan\", \"Feb\", \"Mar\"]\n",
    "\n",
    "#my code here\n",
    "list(set(months))\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [\"Jan\", 3]\n",
    "#my code here\n",
    "dates = set()\n",
    "#dates.add(date)\n",
    "dates.add(tuple(date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple dictionary lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Most common lexical need in computational linguistics: word counts\n",
    "\n",
    "Easy way to build a dictionary of counts when you've got a list of words: [Counters](https://docs.python.org/3/library/collections.html#collections.Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#my code here\n",
    "counts = Counter(brown.words())\n",
    "#my code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[\"niki\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.update(treebank.words())\n",
    "counts[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But sometimes not practical because what you are counting isn't an iterable or you want to do some operation before counting. A normal Python dict is fine, but each value need to be initialized to zero. One solution: the *get* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69971\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    # my code here\n",
    "    #if word not in counts:\n",
    "    #    counts[word] = 0\n",
    "    counts[word] = counts.get(word, 0) + 1\n",
    "\n",
    "print(counts[\"the\"])\n",
    "    # my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Count the first words of sentences in the Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789\n"
     ]
    }
   ],
   "source": [
    "first_word_count = {}\n",
    "for sent in brown.sents():\n",
    "    # your code here\n",
    "    first_word_count[sent[0]] = first_word_count.get(sent[0], 0) + 1\n",
    "    # your code here\n",
    "    \n",
    "print(first_word_count[\"And\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another very common need: assign a index (an integer) to each word, for looking up in data structures like matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict = {}\n",
    "# my code here\n",
    "for word in counts:\n",
    "    index_dict[word] = len(index_dict)\n",
    "# my code here\n",
    "    \n",
    "index_dict[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In these cases, you will often need a reversed index as well. The `items` method for dictionaries is useful if you are iterating over an existing dictionary and want to access both key and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V-1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_index_dict = {}\n",
    "\n",
    "#my code here\n",
    "for word, index in index_dict.items():\n",
    "    rev_index_dict[index] = word\n",
    "    \n",
    "rev_index_dict[9573]\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can do this with the `keys()` and `values()` methods, which provide iterators over the keys and values of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 56057; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7f97e5fe3455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrev_index_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrev_index_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9573\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 56057; 2 is required"
     ]
    }
   ],
   "source": [
    "rev_index_dict = dict((index_dict.values(), index_dict.keys()))\n",
    "rev_index_dict[9573]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Complex lexicons\n",
    "\n",
    "\n",
    "Sometimes lexicons are more complex and might be represented as multiple recursive Python datatypes. For example, instead of a single counts, you might have a list of word senses, which are actually dictionaries of properties (including part-of-speech and a counts of that word sense in a corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# provided code\n",
    "mini_sense_lexicon = {\"bear\":[{\"POS\":\"noun\",\"animate\":True,\"count\":634,\"gloss\":\"A big furry animal\"},\n",
    "                              {\"POS\":\"verb\",\"transitive\":True,\"count\":294, \"past tense\":\"bore\", \"past participle\":\"borne\", \"gloss\":\"to endure\"}],\n",
    "                      \"slug\":[{\"POS\":\"noun\",\"animate\":True,\"count\":34, \"gloss\":\"A slimy animal\"},\n",
    "                              {\"POS\":\"verb\",\"transitive\":True,\"count\":3, \"gloss\": \"to hit\"}],\n",
    "                      \"back\":[{\"POS\":\"noun\",\"animate\":False,\"count\":12,\"gloss\":\"a body part\"},\n",
    "                              {\"POS\":\"noun\",\"animate\":False,\"count\":43, \"gloss\":\"the rear of a place\"},\n",
    "                              {\"POS\":\"verb\",\"transitive\":True,\"count\":5, \"gloss\":\"to support\"},\n",
    "                              {\"POS\":\"adverb\",\"count\":47,\"gloss\":\"in a returning fashion\"}],\n",
    "                      \"good\":[{\"POS\":\"noun\",\"animate\":False,\"count\":19,\"gloss\":\"a thing of value\"},\n",
    "                              {\"POS\":\"adjective\", \"count\":1293,\"gloss\":\"positive\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These can be tricky to navigate. Let's answer the following questions by accessing the information in data structure:\n",
    "\n",
    "How many senses does \"back\" have in this lexicon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mini_sense_lexicon[\"back\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the most common sense of back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in a returning fashion'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_count = 0\n",
    "gloss = \"\"\n",
    "\n",
    "for feature_dict in mini_sense_lexicon[\"back\"]:\n",
    "    if feature_dict[\"count\"] > highest_count:\n",
    "        highest_count = feature_dict[\"count\"]\n",
    "        gloss = feature_dict[\"gloss\"]\n",
    "gloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Does \"slug\" have an adjectival sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_adjective = False\n",
    "for feature_dict in mini_sense_lexicon[\"slug\"]:\n",
    "    if feature_dict[\"POS\"] == \"adjective\":\n",
    "        has_adjective = True\n",
    "has_adjective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which words have a verb sense with an irregular past tense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear\n"
     ]
    }
   ],
   "source": [
    "for word, pos_list in mini_sense_lexicon.items():\n",
    "    for feature_dict in pos_list:\n",
    "        if \"past tense\" in feature_dict:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Which words mention the word animal in one of their glosses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear\n",
      "slug\n"
     ]
    }
   ],
   "source": [
    "for word, pos_list in mini_sense_lexicon.items():\n",
    "    for feature_dict in pos_list:\n",
    "        if \"animal\" in feature_dict[\"gloss\"]:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK lexicons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NLTK has a lot of useful lexicons. Most are word lists. Note that they are listed under corpora and have the same interface; note that they need to be converted to sets if you want to use them for look up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Stopwords\n",
    "\n",
    "Lists of closed-class/function words in various languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#provided code \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"french\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Swadesh\n",
    "\n",
    "words for 200 common concepts from large list of languages, used for historical linguistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "from nltk.corpus import swadesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be',\n",
       " 'bg',\n",
       " 'bs',\n",
       " 'ca',\n",
       " 'cs',\n",
       " 'cu',\n",
       " 'de',\n",
       " 'en',\n",
       " 'es',\n",
       " 'fr',\n",
       " 'hr',\n",
       " 'it',\n",
       " 'la',\n",
       " 'mk',\n",
       " 'nl',\n",
       " 'pl',\n",
       " 'pt',\n",
       " 'ro',\n",
       " 'ru',\n",
       " 'sk',\n",
       " 'sl',\n",
       " 'sr',\n",
       " 'sw',\n",
       " 'uk']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swadesh.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ich\n",
      "you (singular), thou du, Sie\n",
      "he er\n",
      "we wir\n",
      "you (plural) ihr, Sie\n",
      "they sie\n",
      "this dieses\n",
      "that jenes\n",
      "here hier\n",
      "there dort\n",
      "who wer\n",
      "what was\n",
      "where wo\n",
      "when wann\n",
      "how wie\n",
      "not nicht\n",
      "all alle\n",
      "many viele\n",
      "some einige\n",
      "few wenige\n",
      "other andere\n",
      "one eins\n",
      "two zwei\n",
      "three drei\n",
      "four vier\n",
      "five fünf\n",
      "big groß\n",
      "long lang\n",
      "wide breit, weit\n",
      "thick dick\n",
      "heavy schwer\n",
      "small klein\n",
      "short kurz\n",
      "narrow eng\n",
      "thin dünn\n",
      "woman Frau\n",
      "man (adult male) Mann\n",
      "man (human being) Mensch\n",
      "child Kind\n",
      "wife Frau, Ehefrau\n",
      "husband Mann, Ehemann\n",
      "mother Mutter\n",
      "father Vater\n",
      "animal Tier\n",
      "fish Fisch\n",
      "bird Vogel\n",
      "dog Hund\n",
      "louse Laus\n",
      "snake Schlange\n",
      "worm Wurm\n",
      "tree Baum\n",
      "forest Wald\n",
      "stick Stock\n",
      "fruit Frucht\n",
      "seed Samen\n",
      "leaf Blatt\n",
      "root Wurzel\n",
      "bark (from tree) Rinde\n",
      "flower Blume\n",
      "grass Gras\n",
      "rope Seil\n",
      "skin Haut\n",
      "meat Fleisch\n",
      "blood Blut\n",
      "bone Knochen\n",
      "fat (noun) Fett\n",
      "egg Ei\n",
      "horn Horn\n",
      "tail Schwanz\n",
      "feather Feder\n",
      "hair Haar\n",
      "head Kopf, Haupt\n",
      "ear Ohr\n",
      "eye Auge\n",
      "nose Nase\n",
      "mouth Mund\n",
      "tooth Zahn\n",
      "tongue Zunge\n",
      "fingernail Fingernagel\n",
      "foot Fuß\n",
      "leg Bein\n",
      "knee Knie\n",
      "hand Hand\n",
      "wing Flügel\n",
      "belly Bauch\n",
      "guts Eingeweide, Innereien\n",
      "neck Hals\n",
      "back Rücken\n",
      "breast Brust\n",
      "heart Herz\n",
      "liver Leber\n",
      "drink trinken\n",
      "eat essen\n",
      "bite beißen\n",
      "suck saugen\n",
      "spit spucken\n",
      "vomit erbrechen\n",
      "blow blasen\n",
      "breathe atmen\n",
      "laugh lachen\n",
      "see sehen\n",
      "hear hören\n",
      "know (a fact) wissen\n",
      "think denken\n",
      "smell riechen\n",
      "fear fürchten\n",
      "sleep schlafen\n",
      "live leben\n",
      "die sterben\n",
      "kill töten\n",
      "fight kämpfen\n",
      "hunt jagen\n",
      "hit schlagen\n",
      "cut schneiden\n",
      "split spalten\n",
      "stab stechen\n",
      "scratch kratzen\n",
      "dig graben\n",
      "swim schwimmen\n",
      "fly (verb) fliegen\n",
      "walk gehen\n",
      "come kommen\n",
      "lie liegen\n",
      "sit sitzen\n",
      "stand stehen\n",
      "turn drehen\n",
      "fall fallen\n",
      "give geben\n",
      "hold halten\n",
      "squeeze quetschen\n",
      "rub reiben\n",
      "wash waschen\n",
      "wipe wischen\n",
      "pull ziehen\n",
      "push drücken\n",
      "throw werfen\n",
      "tie binden\n",
      "sew nähen\n",
      "count zählen\n",
      "say sagen\n",
      "sing singen\n",
      "play spielen\n",
      "float schweben\n",
      "flow fließen\n",
      "freeze frieren\n",
      "swell schwellen\n",
      "sun Sonne\n",
      "moon Mond\n",
      "star Stern\n",
      "water Wasser\n",
      "rain Regen\n",
      "river Fluß\n",
      "lake See\n",
      "sea Meer, See\n",
      "salt Salz\n",
      "stone Stein\n",
      "sand Sand\n",
      "dust Staub\n",
      "earth Erde\n",
      "cloud Wolke\n",
      "fog Nebel\n",
      "sky Himmel\n",
      "wind Wind\n",
      "snow Schnee\n",
      "ice Eis\n",
      "smoke Rauch\n",
      "fire Feuer\n",
      "ashes Asche\n",
      "burn brennen\n",
      "road Straße\n",
      "mountain Berg\n",
      "red rot\n",
      "green grün\n",
      "yellow gelb\n",
      "white weiß\n",
      "black schwarz\n",
      "night Nacht\n",
      "day Tag\n",
      "year Jahr\n",
      "warm warm\n",
      "cold kalt\n",
      "full voll\n",
      "new neu\n",
      "old alt\n",
      "good gut\n",
      "bad schlecht\n",
      "rotten verrottet\n",
      "dirty schmutzig\n",
      "straight gerade\n",
      "round rund\n",
      "sharp scharf\n",
      "dull stumpf\n",
      "smooth glatt\n",
      "wet nass, feucht\n",
      "dry trocken\n",
      "correct richtig\n",
      "near nah, nahe\n",
      "far weit, fern\n",
      "right rechts\n",
      "left links\n",
      "at bei, an\n",
      "in in\n",
      "with mit\n",
      "and und\n",
      "if wenn, falls, ob\n",
      "because weil\n",
      "name Name\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(swadesh.words(\"en\"))):\n",
    "    print(swadesh.words(\"en\")[i], swadesh.words(\"de\")[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Names\n",
    "\n",
    "Lists of mostly English names, divided by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zonnya',\n",
       " 'Zora',\n",
       " 'Zorah',\n",
       " 'Zorana',\n",
       " 'Zorina',\n",
       " 'Zorine',\n",
       " 'Zsa Zsa',\n",
       " 'Zsazsa',\n",
       " 'Zulema',\n",
       " 'Zuzana']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.words(\"female.txt\")[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Opinion Lexicon\n",
    "\n",
    "Positive and negative word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "from nltk.corpus import opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative-words.txt', 'positive-words.txt']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_lexicon.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_lexicon.words('negative-words.txt')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CMU Pronouncing Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A list of pronounciations for each English word string\n",
    "* Pronounciations are a list of ARPAbet phones\n",
    "* Araphet phones are strings which are alphabetic except for numbers at the end of the vowels\n",
    "* The numbers indicate stress\n",
    "\n",
    "Let's look at a few entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#provided code\n",
    "from nltk.corpus import cmudict\n",
    "p_dict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R', 'EH1', 'D'], ['R', 'IY1', 'D']]\n"
     ]
    }
   ],
   "source": [
    "print(p_dict[\"read\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['IH1', 'N', 'D', 'EH0', 'K', 'S']]\n"
     ]
    }
   ],
   "source": [
    "print(p_dict[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's get some basic stats for this lexicon: total entries, average number of pronounciations per word, average number of phones per pronounciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "phones = 0\n",
    "pronounciation_count = 0\n",
    "for pronounciations in p_dict.values():\n",
    "    # my code here\n",
    "    pronounciation_count += len(pronounciations)\n",
    "    for pronounciation in pronounciations:\n",
    "        phones += len(pronounciation)\n",
    "    # my code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123455"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0832854076384109"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounciation_count/len(p_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3850542482633825"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones/pronounciation_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Count how often each English phone appears in this lexicon. We need to make sure to strip off the stress markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AH': 71410, 'EY': 13521, 'F': 13748, 'AO': 11290, 'R': 46046, 'T': 48549, 'UW': 9736, 'W': 8864, 'N': 60564, 'IH': 50093, 'P': 19715, 'L': 49479, 'AA': 24546, 'B': 21057, 'ER': 29027, 'G': 13553, 'K': 42502, 'S': 50427, 'EH': 27398, 'TH': 2902, 'M': 29347, 'D': 32389, 'V': 10742, 'Z': 27842, 'IY': 34504, 'AE': 21804, 'OW': 19047, 'NG': 9865, 'SH': 8700, 'HH': 9319, 'AW': 3408, 'AY': 11313, 'JH': 6404, 'Y': 5171, 'CH': 4960, 'ZH': 560, 'UH': 2273, 'DH': 576, 'OY': 1267}\n"
     ]
    }
   ],
   "source": [
    "phone_counts = {}\n",
    "for pronounciations in p_dict.values():\n",
    "    for pronounciation in pronounciations:\n",
    "        # your code here\n",
    "        for phone in pronounciation:\n",
    "            if phone[-1].isdigit():\n",
    "                phone = phone[:-1]\n",
    "            phone_counts[phone] = phone_counts.get(phone, 0) + 1\n",
    "        # your code here\n",
    "            \n",
    "print(phone_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## File IO for lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lists of words are typically stored as lines of a file. Let's write out the list of English possesive pronouns, and read them back in by iterating one line at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "his\n",
      "her\n",
      "my\n",
      "your\n",
      "their\n",
      "our\n",
      "its\n"
     ]
    }
   ],
   "source": [
    "pps = [\"his\", \"her\", \"my\", \"your\", \"their\", \"our\", \"its\"]\n",
    "\n",
    "#my code here\n",
    "fout = open(\"possessive_pronouns.txt\",\"w\")\n",
    "for pp in pps:\n",
    "    fout.write(pp + \"\\n\")\n",
    "fout.close()\n",
    "\n",
    "f = open(\"possessive_pronouns.txt\")\n",
    "for line in f:\n",
    "    print(line.strip())\n",
    "f.close()\n",
    "\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For lexicons which are simple dictionaries, the most common format is a tab delimited file. Let's create one for the small count dict below, and again read it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': '62713', 'quick': '66', 'fox': '9'}\n"
     ]
    }
   ],
   "source": [
    "counts = {\"the\":62713, \"quick\":66, \"fox\":9}\n",
    "\n",
    "# my code here\n",
    "fout = open(\"counts.txt\",\"w\")\n",
    "for word, count in counts.items():\n",
    "    fout.write(word + \"\\t\" + str(count) + \"\\n\")\n",
    "fout.close()\n",
    "\n",
    "f = open(\"counts.txt\")\n",
    "\n",
    "new_counts = {}\n",
    "\n",
    "for line in f:\n",
    "    word, count = line.strip().split(\"\\t\")\n",
    "    new_counts[word] = str(count)\n",
    "    \n",
    "print(new_counts)\n",
    "# my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For complex lexicons, we should use a Python package which allows us to save the entire data structure in one go. There are two good choices for this: the [json](https://docs.python.org/3/library/json.html) package saves a Python data structure in a human-readable form, whereas the [pickle](https://docs.python.org/3/library/pickle.html) package saves it in a compact binary form. The two packages have essentially the same interface, so we'll just look at json (where we can inspect the file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bear': [{'POS': 'noun', 'animate': True, 'count': 634, 'gloss': 'A big furry animal'}, {'POS': 'verb', 'transitive': True, 'count': 294, 'past tense': 'bore', 'past participle': 'borne', 'gloss': 'to endure'}], 'slug': [{'POS': 'noun', 'animate': True, 'count': 34, 'gloss': 'A slimy animal'}, {'POS': 'verb', 'transitive': True, 'count': 3, 'gloss': 'to hit'}], 'back': [{'POS': 'noun', 'animate': False, 'count': 12, 'gloss': 'a body part'}, {'POS': 'noun', 'animate': False, 'count': 43, 'gloss': 'the rear of a place'}, {'POS': 'verb', 'transitive': True, 'count': 5, 'gloss': 'to support'}, {'POS': 'adverb', 'count': 47, 'gloss': 'in a returning fashion'}], 'good': [{'POS': 'noun', 'animate': False, 'count': 19, 'gloss': 'a thing of value'}, {'POS': 'adjective', 'count': 1293, 'gloss': 'positive'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#my code here\n",
    "fout = open(\"mini_sense_lexicon.txt\", \"w\")\n",
    "json.dump(mini_sense_lexicon, fout)\n",
    "fout.close()\n",
    "\n",
    "f = open(\"mini_sense_lexicon.txt\")\n",
    "new_mini_sense_lexicon = json.load(f)\n",
    "f.close()\n",
    "\n",
    "print(new_mini_sense_lexicon)\n",
    "\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: pick some words with form a natural class. Create a text file with those words, read them in, and then count how often words of that type appear an NLTK corpus of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18052\n"
     ]
    }
   ],
   "source": [
    "f = open(\"possessive_pronouns.txt\")\n",
    "pps = set()\n",
    "for line in f:\n",
    "    pps.add(line.strip())\n",
    "    \n",
    "pps_count = 0\n",
    "\n",
    "for word in brown.words():\n",
    "    if word.lower() in pps:\n",
    "        pps_count += 1\n",
    "print(pps_count)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
